{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Batch Correction and Integration using FEATS\n",
    "\n",
    "In this code example, we describe how to perform batch correction and integration using FEATS. We will use an artificial dataset, however, the same steps can be followed for any dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "Firstly, we need to import libraries to enable us to use the modules. For batch correction, we import `CorrectBatches` which is going to perform correction or allignment, and `IntegrateBatches` which is going to find common genes among the datasets and combine/merge all the datasets into one. For more information on these functions please use `help()` command by passing the function name as the argument, e.g., `help(IntegrateBatches)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Import our libraries\n",
    "from singlecelldata import SingleCell\n",
    "from feats import CorrectBatches, IntegrateBatches\n",
    "\n",
    "# Visualization \n",
    "from scplotlib import tSNEPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import datasets\n",
    "\n",
    "The second step is to import the datasets into the notebook environment. To do this we will use the Pandas `read_csv` function to read the data from csv format files into dataframes. Here we have two batches, batch1 and batch2. Apart from the gene expression matrix we will also import cell data which consists of the cell type information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "\n",
    "batch1 = pd.read_csv(\"data/batch1.csv\", index_col=0)\n",
    "batch2 = pd.read_csv(\"data/batch2ii.csv\", index_col=0)\n",
    "\n",
    "b1_celldata = pd.read_csv(\"data/batch1_labels.csv\", index_col=0)\n",
    "b1_celldata = pd.DataFrame(b1_celldata.values, columns = [\"cell type\"])\n",
    "\n",
    "b2_celldata = pd.read_csv(\"data/batch2ii_labels.csv\", index_col=0)\n",
    "b2_celldata = b2_celldata.T\n",
    "b2_celldata = pd.DataFrame(b2_celldata.values, columns = [\"cell type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SingleCell objects from the data\n",
    "\n",
    "Next, we will create SingleCell objects from the data using the `SingleCell` class. Note here that we are only passing the data and  the celldata dataframes into the class constructor. We are not passing any genedata dataframe. The constructor will automatically create a genedata dataframe and store gene names as 'gene1', 'gene2', ..., 'gened' under the data column 'gene_names'. We can call the `print()` method to see a summary of the SingleCell object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "Dataset:  simulation2\n",
      "------------------------------------------------------------------------------\n",
      "Dimension:  (100, 1000)\n",
      "Cell Metadata:  ['cell type']\n",
      "Gene Metadata:  ['gene_names']\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create a single cell object  \n",
    "\n",
    "bat1 = SingleCell(dataset = \"simulation1\", data = batch1, celldata = b1_celldata)\n",
    "bat2 = SingleCell(dataset = \"simulation2\", data = batch2, celldata = b2_celldata)\n",
    "\n",
    "bat2.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of batches\n",
    "\n",
    "To do batch integration, we have to create a Python list of batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all the batches\n",
    "\n",
    "batches = [bat1, bat2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate and merge the batches\n",
    "\n",
    "The next step is to find common genes across the batches before merging them all into one dataset. The datasets can have different number and type of genes and cells. The `IntegrateBatches` function will attempt to find common genes across the datasets and merge the datasets into one SingleCell object. If no common genes are found a message will be displayed and the function will exit. We need to pass the batches list into this function as the first argument. The second argument is the name of the data column which stores the gene names in the SingleCell object. This needs to be passed as alist of string with the length same as the number of datasets as each dataset can store the gene name information under different names. We can also call `print()` on the integrated dataset to see a summary. We can see that another data column, 'batch', has been added to cell metadata to include batch information. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrating Batches . . .\n",
      "Number of common genes in all batches:  100\n",
      "Merging Batches . . .\n"
     ]
    }
   ],
   "source": [
    "# Integrate batches and merge into 1 SingleCell dataset\n",
    "\n",
    "batches = IntegrateBatches(batches, name_by = ['gene_names', 'gene_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "Dataset:  simulation1+simulation2\n",
      "------------------------------------------------------------------------------\n",
      "Dimension:  (100, 2000)\n",
      "Cell Metadata:  ['cell type' 'batch']\n",
      "Gene Metadata:  ['gene_names']\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "batches.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise batches before correction/allignment\n",
    "\n",
    "We can visualize the integrated datasets before performation correction. We use the `tSNEPlot` function to generate a 2D scatter plot. We can see that the same cell types in different batches do not appear together or are not alligned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying chart at http://localhost:17325/\n"
     ]
    }
   ],
   "source": [
    "fig1 = tSNEPlot(batches, \n",
    "                marker_by = 'batch', \n",
    "                color_by = 'cell type', \n",
    "                tsne_init = 'pca')\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run batch correction\n",
    "\n",
    "To run batch correction, we use the `CorrectBatches` function. The first argument is the integrated batches as one SingleCell object. The second argument is `correct_order`, were the user can specify the order of the batches to use for correction. The `CorrectBatches` function will assign the first batch in the list as the reference batch and the second as the target batch. It will correct two batches at a time, and merge the first two to be used as the reference batch for correcting the third batch and so on. In this case, we only have two batches, so 'simulation1' will be the reference batch and 'simulation2' will be the target batch. The next parameter is the `sigma` parameter for the Gaussian kernel which is used to smooth correction vectors. The last parameter is `svd_dim`, the number of eigenvectors to select for checking the orthogonality assumption in MNN batch correction. For more info, run `help(CorrectBatches)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1000)\n",
      "Correcting batches < simulation1  and  simulation2 >\n",
      "Merging Batches . . .\n"
     ]
    }
   ],
   "source": [
    "batches = CorrectBatches(batches, \n",
    "                         correct_order = ['simulation1', 'simulation2'], \n",
    "                         sigma = 10, \n",
    "                         svd_dim = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize corrected/aligned batches\n",
    "\n",
    "Finally, we can do `tSNEPlot` again to visualize the corrected batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing ' t-SNE 1 ' from CellData assay\n",
      "Removing ' t-SNE 2 ' from CellData assay\n",
      "Displaying chart at http://localhost:17325/\n"
     ]
    }
   ],
   "source": [
    "fig2 = tSNEPlot(batches, \n",
    "                color_by = 'cell type', \n",
    "                marker_by = 'batch', \n",
    "                tsne_init = 'pca')\n",
    "fig2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
